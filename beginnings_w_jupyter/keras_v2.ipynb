{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2            # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm_notebook #from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "#D:/cnntry/air_data/trainairplane/  #training pictures of airplane\n",
    "#D:/cnntry/air_data/annot_train    #annotation files of training airplane pictures\n",
    "\n",
    "#D:/cnntry/air_data/valairplane/\n",
    "#D:/cnntry/air_data/annot_val/\n",
    "\n",
    "\n",
    "TRAIN_dir = 'D:/cnntry/air_data/trainairplane'\n",
    "TRAIN_annot_dir = 'D:/cnntry/air_data/annot_train'\n",
    "TRAIN_DIR = 'D:\\cnntry\\\\train'\n",
    "\n",
    "#TEST_DIR = 'D:\\cnntry\\\\test'\n",
    "TEST_DIR ='andrej/datasets/cats-and-dogs/1/home/test'\n",
    "\n",
    "DATA_file= 'train_airdata.npy' \n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'cnnv1-{}-{}.model'.format(LR, 'idk') # just so we remember which saved model is which, sizes must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#(train_images, train_labels), (validation_images, validation_labels) = datasets.mnist.load_data()\n",
    "\n",
    "#train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "#train_images = train_images.astype('float32') / 255\n",
    "\n",
    "#validation_images = validation_images.reshape((10000, 28, 28, 1))\n",
    "#validation_images = validation_images.astype('float32') / 255\n",
    "\n",
    "#train_labels = to_categorical(train_labels)\n",
    "#validation_labels = to_categorical(validation_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETWORK MODEL \n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(16, 3, strides=(1, 1), padding='same', kernel_regularizer= l2(5e-4),input_shape=(416, 416, 3))) \n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "filters=[32,64,128,256,512]\n",
    "for fil in filters:\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "    model.add(layers.Conv2D(fil, 3, strides=(1, 1), padding='same', kernel_regularizer= l2(5e-4))) \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(256, 3, strides=(1, 1), padding='same', kernel_regularizer= l2(5e-4)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Conv2D(30, 3, strides=(1, 1), padding='same', activation='linear', kernel_regularizer= l2(5e-4)))  \n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(validation_images, validation_labels)\n",
    "\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-05*10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9*16*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS FUNCTION\n",
    "# the mask is 1 for detectors that have an object, 0 otherwise\n",
    "mask = (target.conf == 1)\n",
    "\n",
    "# compute IOUs between each detector's predicted box and\n",
    "# the corresponding ground-truth box from the target tensor\n",
    "ious = IOU(target.coords, grid.coords)\n",
    "\n",
    "# compute the loss terms for the entire grid at once:\n",
    "object_loss = sum(mask * (ious - sigmoid(grid.conf))**2)\n",
    "coord_loss = sum(mask * (target.coords - grid.coords)**2)\n",
    "class_loss = sum(mask * (target.class - softmax(grid.class))**2)\n",
    "no_object_loss = sum((1 - mask) * (0 - sigmoid(grid.conf))**2)\n",
    "\n",
    "loss = no_object_scale * sum(no_object_loss) + \n",
    "          object_scale * sum(object_loss) + \n",
    "           coord_scale * sum(coord_loss) + \n",
    "           class_scale * sum(class_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO\n",
    "#z loss function vyjebat classes\n",
    "#scalenut poslednu layer na moj output\n",
    "#k means clustering = getting nice anchors https://machinethink.net/blog/object-detection/\n",
    "#reading input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
